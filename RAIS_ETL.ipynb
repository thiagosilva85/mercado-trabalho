{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923935e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa9e9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sqlalchemy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import time as tm\n",
    "import sys\n",
    "\n",
    "from ftplib import FTP\n",
    "import os\n",
    "import re\n",
    "import py7zr\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba0f322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9\n"
     ]
    }
   ],
   "source": [
    "print(sys.version.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "415ff5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão bem sucedida ao servidor FTP: ftp.mtps.gov.br\n"
     ]
    }
   ],
   "source": [
    "# Verificando se o servidor FTP está ativo\n",
    "server = \"ftp.mtps.gov.br\"\n",
    "\n",
    "try:\n",
    "    # Conecta ao servidor FTP\n",
    "    ftp = FTP(server)\n",
    "    # Faz login (opcional)\n",
    "    # ftp.login(\"usuario\", \"senha\")\n",
    "    # Verifica se a conexão foi bem sucedida\n",
    "    if ftp.getwelcome():\n",
    "        print(\"Conexão bem sucedida ao servidor FTP:\", server)\n",
    "    # Fecha a conexão com o servidor FTP\n",
    "    ftp.quit()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Falha na conexão com o servidor FTP:\", server)\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a88dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/thiago.silva/TCC/RAIS'\n",
    "path_tmp = path+'/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "974241c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando arquivo de 2010...\n",
      "Baixando arquivo de 2011...\n",
      "Baixando arquivo de 2012...\n",
      "Baixando arquivo de 2013...\n",
      "Baixando arquivo de 2014...\n",
      "Baixando arquivo de 2015...\n",
      "Baixando arquivo de 2016...\n",
      "Baixando arquivo de 2017...\n",
      "Baixando arquivo de 2018...\n",
      "Baixando arquivo de 2019...\n",
      "Baixando arquivo de 2020...\n",
      "Baixando arquivo de 2021...\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# TRECHO DE CÓDIGO APENAS PARA O DOWNLOAD DOS ARQUIVOS #\n",
    "########################################################\n",
    "\n",
    "path = 'C:/Users/thiago.silva/TCC/RAIS'\n",
    "path_tmp = path+'/temp'\n",
    "\n",
    "ftp = FTP('ftp.mtps.gov.br')\n",
    "ftp.login()\n",
    "ftp.cwd('/pdet/microdados/RAIS')\n",
    "\n",
    "anos = [ano for ano in range(2010,2022)]\n",
    "\n",
    "# define o diretório local onde os arquivos serão salvos\n",
    "local_dir = os.path.join(os.getcwd(), \"dados_rais\")\n",
    "\n",
    "if not os.path.exists(local_dir):\n",
    "    os.makedirs(local_dir)\n",
    "\n",
    "for ano in anos:\n",
    "    ftp.cwd(f'/pdet/microdados/RAIS/{ano}')\n",
    "    \n",
    "    print(f\"Baixando arquivo de {ano}...\")        \n",
    "    for filename in ftp.nlst():\n",
    "        if 'ESTAB' in filename or 'ESTB' in filename or 'Estb' in filename:\n",
    "            year_match = re.search(r'\\b(20\\d{2})\\b', filename)  # Encontra um padrão de quatro dígitos numéricos que representam o ano\n",
    "\n",
    "            if year_match:\n",
    "                year = year_match.group(1)  # Obtém o ano encontrado na string\n",
    "            else:\n",
    "                year = ano  # Substitua 'YEAR' pelo ano que você deseja adicionar caso não haja um ano no nome do arquivo\n",
    "\n",
    "                # Adiciona o ano ao nome do arquivo\n",
    "                new_filename = f\"ESTB{year}.7z\"\n",
    "\n",
    "                local_path = os.path.join(path_tmp, new_filename)  # Substitua '/caminho/do/diretorio' pelo caminho desejado\n",
    "                with open(local_path, 'wb') as file:\n",
    "                    ftp.retrbinary('RETR ' + filename, file.write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c93697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo ESTB2010.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2010.7z excluído.\n",
      "Arquivo ESTB2011.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2011.7z excluído.\n",
      "Arquivo ESTB2012.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2012.7z excluído.\n",
      "Arquivo ESTB2013.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2013.7z excluído.\n",
      "Arquivo ESTB2014.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2014.7z excluído.\n",
      "Arquivo ESTB2015.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2015.7z excluído.\n",
      "Arquivo ESTB2016.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2016.7z excluído.\n",
      "Arquivo ESTB2017.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2017.7z excluído.\n",
      "Arquivo ESTB2018.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2018.7z excluído.\n",
      "Arquivo ESTB2019.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2019.7z excluído.\n",
      "Arquivo ESTB2020.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2020.7z excluído.\n",
      "Arquivo ESTB2021.7z descompactado para C:/Users/thiago.silva/TCC/RAIS\n",
      "Arquivo ESTB2021.7z excluído.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(path_tmp):\n",
    "    if filename.endswith('.7z'):\n",
    "        arquivo_7z = os.path.join(path_tmp, filename)\n",
    "\n",
    "        with py7zr.SevenZipFile(arquivo_7z, mode='r') as z:\n",
    "            z.extractall(path=path)\n",
    "\n",
    "        print(f\"Arquivo {filename} descompactado para {path}\")\n",
    "\n",
    "        arquivos_txt = [f for f in os.listdir(path) if f.startswith('ESTB') or f.startswith('Estb') and f.endswith('.txt')]\n",
    "        years = [int(arquivo_txt[4:8]) for arquivo_txt in arquivos_txt]\n",
    "        last_year = max(years)\n",
    "        \n",
    "        arquivo = 'RAIS_ESTAB_PUB.txt'\n",
    "\n",
    "        if os.path.exists(os.path.join(path, arquivo)):\n",
    "            novo_nome_arquivo = f'ESTB{last_year + 1}.txt'\n",
    "            caminho_novo_nome_arquivo = os.path.join(path, novo_nome_arquivo)\n",
    "            os.rename(os.path.join(path, arquivo), caminho_novo_nome_arquivo)\n",
    "\n",
    "        # Exclui o arquivo 7z após a descompactação\n",
    "        os.remove(arquivo_7z)\n",
    "        print(f\"Arquivo {filename} excluído.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a52b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando nome do arquivo de 2012\n",
    "antigo2012 = 'Estb2012.txt'\n",
    "novo2012 = 'ESTB2012.txt'\n",
    "os.rename(os.path.join(path, antigo2012), os.path.join(path, novo2012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ff3c348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo ESTB2010.txt renomeado para ESTB2010.csv.\n",
      "Arquivo ESTB2011.txt renomeado para ESTB2011.csv.\n",
      "Arquivo ESTB2012.txt renomeado para ESTB2012.csv.\n",
      "Arquivo ESTB2013.txt renomeado para ESTB2013.csv.\n",
      "Arquivo ESTB2014.txt renomeado para ESTB2014.csv.\n",
      "Arquivo ESTB2015.txt renomeado para ESTB2015.csv.\n",
      "Arquivo ESTB2016.txt renomeado para ESTB2016.csv.\n",
      "Arquivo ESTB2017.txt renomeado para ESTB2017.csv.\n",
      "Arquivo ESTB2018.txt renomeado para ESTB2018.csv.\n",
      "Arquivo ESTB2019.txt renomeado para ESTB2019.csv.\n",
      "Arquivo ESTB2020.txt renomeado para ESTB2020.csv.\n",
      "Arquivo ESTB2021.txt renomeado para ESTB2021.csv.\n",
      "Todos os arquivos foram renomeados para a extensão .csv.\n"
     ]
    }
   ],
   "source": [
    "# Lista de arquivos extraídos\n",
    "arquivos = [f for f in os.listdir(path) if f.startswith('ESTB') and f.endswith('.txt')]\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    novo_nome_arquivo = arquivo[:-4] + \".csv\"\n",
    "    caminho_arquivo_original = os.path.join(path, arquivo)\n",
    "    caminho_arquivo_renomeado = os.path.join(path, novo_nome_arquivo)\n",
    "    os.rename(caminho_arquivo_original, caminho_arquivo_renomeado)\n",
    "    print(f\"Arquivo {arquivo} renomeado para {novo_nome_arquivo}.\")\n",
    "\n",
    "print(\"Todos os arquivos foram renomeados para a extensão .csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3cba78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\3418199052.py:6: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';', encoding='cp1252')\n",
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\3418199052.py:6: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';', encoding='cp1252')\n",
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\3418199052.py:6: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';', encoding='cp1252')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna de ano adicionada em todos os arquivos CSV.\n"
     ]
    }
   ],
   "source": [
    "arquivos = [f for f in os.listdir(path) if f.startswith('ESTB') and f.endswith('.csv')]\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    ano = arquivo[4:8]\n",
    "    caminho_arquivo = os.path.join(path, arquivo)\n",
    "    df = pd.read_csv(caminho_arquivo, delimiter=';', encoding='cp1252')\n",
    "    df['Ano'] = ano\n",
    "    df.to_csv(caminho_arquivo, sep=';', index=False)\n",
    "\n",
    "print(\"Coluna de ano adicionada em todos os arquivos CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51c0a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\142648608.py:4: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n",
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\142648608.py:4: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n",
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\142648608.py:4: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas únicas de todos os arquivos CSV:\n",
      "['CNAE 95 Classe', 'Ind CEI Vinculado', 'Ind Simples', 'IBGE Subsetor', 'Distritos SP', 'Bairros RJ', 'Regiões Adm DF', 'Qtd Vínculos Estatutários', 'Ind Estab Participa PAT', 'CEP Estab', 'Bairros SP', 'Qtd Vínculos Ativos', 'UF', 'Município', 'Bairros Fortaleza', 'CNAE 2.0 Classe', 'Natureza Jurídica', 'Ind Rais Negativa', 'Tipo Estab', 'Tipo Estab.1', 'Tamanho Estabelecimento', 'Ind Atividade Ano', 'CNAE 2.0 Subclasse', 'Ano', 'Qtd Vínculos CLT']\n"
     ]
    }
   ],
   "source": [
    "todas_colunas = []\n",
    "for arquivo in arquivos:\n",
    "    caminho_arquivo = os.path.join(path, arquivo)\n",
    "    df = pd.read_csv(caminho_arquivo, delimiter=';')\n",
    "    colunas = df.columns.tolist()\n",
    "    todas_colunas.extend(colunas)\n",
    "\n",
    "# Remove as colunas repetidas\n",
    "colunas_unicas = list(set(todas_colunas))\n",
    "\n",
    "print(\"Colunas únicas de todos os arquivos CSV:\")\n",
    "print(colunas_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0316344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do arquivo ESTB2010.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'Ano']\n",
      "Colunas do arquivo ESTB2011.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'Ano']\n",
      "Colunas do arquivo ESTB2012.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'Ano']\n",
      "Colunas do arquivo ESTB2013.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'Ano']\n",
      "Colunas do arquivo ESTB2014.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'IBGE Subsetor', 'CEP Estab', 'Ano']\n",
      "Colunas do arquivo ESTB2015.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'IBGE Subsetor', 'CEP Estab', 'Ano']\n",
      "Colunas do arquivo ESTB2016.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'IBGE Subsetor', 'CEP Estab', 'Ano']\n",
      "Colunas do arquivo ESTB2017.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'IBGE Subsetor', 'CEP Estab', 'Ano']\n",
      "Colunas do arquivo ESTB2018.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'IBGE Subsetor', 'CEP Estab', 'Ano']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\2514611392.py:3: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do arquivo ESTB2019.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'IBGE Subsetor', 'CEP Estab', 'Ano']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\2514611392.py:3: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do arquivo ESTB2020.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'IBGE Subsetor', 'CEP Estab', 'Ano']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_23040\\2514611392.py:3: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do arquivo ESTB2021.csv:\n",
      "['Bairros SP', 'Bairros Fortaleza', 'Bairros RJ', 'CNAE 2.0 Classe', 'CNAE 95 Classe', 'Distritos SP', 'Qtd Vínculos CLT', 'Qtd Vínculos Ativos', 'Qtd Vínculos Estatutários', 'Ind Atividade Ano', 'Ind CEI Vinculado', 'Ind Estab Participa PAT', 'Ind Rais Negativa', 'Ind Simples', 'Município', 'Natureza Jurídica', 'Regiões Adm DF', 'CNAE 2.0 Subclasse', 'Tamanho Estabelecimento', 'Tipo Estab', 'Tipo Estab.1', 'UF', 'IBGE Subsetor', 'CEP Estab', 'Ano']\n"
     ]
    }
   ],
   "source": [
    "for arquivo in arquivos:\n",
    "    caminho_arquivo = os.path.join(path, arquivo)\n",
    "    df = pd.read_csv(caminho_arquivo, delimiter=';')\n",
    "    colunas = df.columns.tolist()\n",
    "\n",
    "    print(f\"Colunas do arquivo {arquivo}:\")\n",
    "    print(colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fb630bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_21984\\367050420.py:8: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n",
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_21984\\367050420.py:8: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n",
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_21984\\367050420.py:8: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n"
     ]
    }
   ],
   "source": [
    "colunas_por_ano = {}\n",
    "\n",
    "for arquivo in os.listdir(path):\n",
    "    if arquivo.startswith('ESTB') and arquivo.endswith(\".csv\"):\n",
    "        ano = arquivo[4:8]\n",
    "        caminho_arquivo = os.path.join(path, arquivo)\n",
    "        \n",
    "        df = pd.read_csv(caminho_arquivo, delimiter=';')\n",
    "        colunas = df.columns.tolist()\n",
    "        \n",
    "        colunas_por_ano[f\"colunas_{ano}\"] = colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b99cccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_2010 = colunas_por_ano[\"colunas_2010\"]\n",
    "colunas_2011 = colunas_por_ano[\"colunas_2011\"]\n",
    "colunas_2012 = colunas_por_ano[\"colunas_2012\"]\n",
    "colunas_2013 = colunas_por_ano[\"colunas_2013\"]\n",
    "colunas_2014 = colunas_por_ano[\"colunas_2014\"]\n",
    "colunas_2015 = colunas_por_ano[\"colunas_2015\"]\n",
    "colunas_2016 = colunas_por_ano[\"colunas_2016\"]\n",
    "colunas_2017 = colunas_por_ano[\"colunas_2017\"]\n",
    "colunas_2018 = colunas_por_ano[\"colunas_2018\"]\n",
    "colunas_2019 = colunas_por_ano[\"colunas_2019\"]\n",
    "colunas_2020 = colunas_por_ano[\"colunas_2020\"]\n",
    "colunas_2021 = colunas_por_ano[\"colunas_2021\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fe8ee70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UF']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = list(set(colunas_2012) ^ set(colunas_2013))\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28b045ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CEP Estab', 'IBGE Subsetor']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = list(set(colunas_2013) ^ set(colunas_2014))\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6716f2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas faltantes adicionadas ao arquivo ESTB2010.csv.\n",
      "Colunas faltantes adicionadas ao arquivo ESTB2011.csv.\n",
      "Colunas faltantes adicionadas ao arquivo ESTB2012.csv.\n",
      "Colunas faltantes adicionadas ao arquivo ESTB2013.csv.\n",
      "Colunas faltantes adicionadas ao arquivo ESTB2014.csv.\n",
      "Conclusão: Colunas faltantes adicionadas em todos os arquivos CSV.\n"
     ]
    }
   ],
   "source": [
    "for ano in range(2010, 2015):\n",
    "    nome_arquivo = f'ESTB{ano}.csv'\n",
    "    caminho_arquivo = os.path.join(path, nome_arquivo)\n",
    "    \n",
    "    if os.path.exists(caminho_arquivo):\n",
    "        df = pd.read_csv(caminho_arquivo, delimiter=';', encoding='cp1252')\n",
    "        df['IBGE Subsetor'] = None\n",
    "        df['CEP Estab'] = None\n",
    "        \n",
    "        if ano < 2014:\n",
    "            df['UF'] = None\n",
    "        \n",
    "        df.to_csv(caminho_arquivo, sep=';', index=False, encoding='cp1252')\n",
    "        print(f\"Colunas faltantes adicionadas ao arquivo {nome_arquivo}.\")\n",
    "    else:\n",
    "        print(f\"Arquivo {nome_arquivo} não encontrado.\")\n",
    "\n",
    "print(\"Conclusão: Colunas faltantes adicionadas em todos os arquivos CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6977746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas ordenadas no arquivo ESTB2010.csv.\n",
      "Colunas ordenadas no arquivo ESTB2011.csv.\n",
      "Colunas ordenadas no arquivo ESTB2012.csv.\n",
      "Colunas ordenadas no arquivo ESTB2013.csv.\n",
      "Colunas ordenadas no arquivo ESTB2014.csv.\n",
      "Conclusão: Colunas ordenadas em todos os arquivos CSV.\n"
     ]
    }
   ],
   "source": [
    "ordem_colunas = colunas_2021\n",
    "\n",
    "for ano in range(2010, 2015):\n",
    "    nome_arquivo = f'ESTB{ano}.csv'\n",
    "    caminho_arquivo = os.path.join(path, nome_arquivo)\n",
    "\n",
    "    if os.path.exists(caminho_arquivo):\n",
    "        df = pd.read_csv(caminho_arquivo, delimiter=';', encoding='cp1252')\n",
    "        df = df.reindex(columns=ordem_colunas)\n",
    "        df.to_csv(caminho_arquivo, sep=';', index=False)\n",
    "        print(f\"Colunas ordenadas no arquivo {nome_arquivo}.\")\n",
    "    else:\n",
    "        print(f\"Arquivo {nome_arquivo} não encontrado.\")\n",
    "\n",
    "print(\"Conclusão: Colunas ordenadas em todos os arquivos CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7db72c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UF']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = list(set(colunas_2012) ^ set(colunas_2013))\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe9813af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CEP Estab', 'IBGE Subsetor']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = list(set(colunas_2013) ^ set(colunas_2014))\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d41e152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CEP Estab', 'UF', 'IBGE Subsetor']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = list(set(colunas_2021) ^ set(colunas_2010))\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a377e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Informações de conexão com o banco Postgres\n",
    "host='dataiesb.iesbtech.com.br'\n",
    "dbname='IESB_Empresas'\n",
    "user='1922120026_TCC_Thiago'\n",
    "password='*********'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccd0d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com o banco de dados realizada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Função para criar conexão no banco\n",
    "def conecta_db():\n",
    "    con = psycopg2.connect(host=host, \n",
    "                         database=dbname,\n",
    "                         user=user, \n",
    "                         password=password)\n",
    "    return con\n",
    "\n",
    "def postgres_test():\n",
    "    try:\n",
    "        con = conecta_db()\n",
    "        con.close()\n",
    "        print(\"Conexão com o banco de dados realizada com sucesso!\")\n",
    "    except:\n",
    "        print(\"A conexão com o banco de dados falhou!\")\n",
    "\n",
    "postgres_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6499643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar tabela no banco\n",
    "def criar_db(sql):\n",
    "    con = conecta_db()\n",
    "    cur = con.cursor()\n",
    "    cur.execute(sql)\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65b06d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela para os dados das RAIS ESTABELECIMENTO\n",
    "sql = '''CREATE TABLE IF NOT EXISTS tb_rais_estabelecimento (\n",
    "cnae_95_classe varchar(255),\n",
    "ind_cei_vinculado varchar(255),\n",
    "ind_simples varchar(255),\n",
    "ibge_subsetor varchar(255),\n",
    "distritos_sp varchar(255),\n",
    "bairros_rj varchar(255),\n",
    "regioes_adm_df varchar(255),\n",
    "qtd_vinculos_estatutarios varchar(255),\n",
    "ind_estab_participa_pat varchar(255),\n",
    "cep_estab varchar(255),\n",
    "bairros_sp varchar(255),\n",
    "qtd_vinculos_ativos varchar(255),\n",
    "uf varchar(255),\n",
    "municipio varchar(255),\n",
    "bairros_fortaleza varchar(255),\n",
    "cnae_2_0_classe varchar(255),\n",
    "natureza_juridica varchar(255),\n",
    "ind_rais_negativa varchar(255),\n",
    "tipo_estab varchar(255),\n",
    "tipo_estab_1 varchar(255),\n",
    "tamanho_estabelecimento varchar(255),\n",
    "ind_atividade_ano varchar(255),\n",
    "cnae_2_0_subclasse varchar(255),\n",
    "ano varchar(255),\n",
    "qtd_vinculos_clt varchar(255)\n",
    "  );'''\n",
    "\n",
    "criar_db(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79250967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_from_stringio(con, year, table):\n",
    "    \"\"\"\n",
    "    Here we are going save the dataframe in memory \n",
    "    and use copy_from() to copy it to the table\n",
    "    \"\"\"\n",
    "    # save dataframe to an in memory buffer\n",
    "    buffer = StringIO()\n",
    "    nome_arquivo = f'ESTB{year}.csv'\n",
    "    caminho_arquivo = os.path.join(path, nome_arquivo)\n",
    "    df = pd.read_csv(caminho_arquivo, delimiter=';')\n",
    "    df.to_csv(buffer, index=False, header=False)\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    cursor = con.cursor()\n",
    "    try:\n",
    "        cursor.copy_from(buffer, table, sep=\",\")\n",
    "        con.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        con.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(f\"copy_from_stringio() done for {year}\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa01ac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy_from_stringio() done for 2010\n",
      "Arquivo de 2010 incluído no banco em 1052.3579628001899 segundos.\n",
      "copy_from_stringio() done for 2011\n",
      "Arquivo de 2011 incluído no banco em 751.9692470999435 segundos.\n",
      "copy_from_stringio() done for 2012\n",
      "Arquivo de 2012 incluído no banco em 810.372569900006 segundos.\n",
      "copy_from_stringio() done for 2013\n",
      "Arquivo de 2013 incluído no banco em 748.4472542998847 segundos.\n",
      "copy_from_stringio() done for 2014\n",
      "Arquivo de 2014 incluído no banco em 529.3301528000738 segundos.\n",
      "copy_from_stringio() done for 2015\n",
      "Arquivo de 2015 incluído no banco em 748.6352554999758 segundos.\n",
      "copy_from_stringio() done for 2016\n",
      "Arquivo de 2016 incluído no banco em 927.6303840999026 segundos.\n",
      "copy_from_stringio() done for 2017\n",
      "Arquivo de 2017 incluído no banco em 885.4010523001198 segundos.\n",
      "copy_from_stringio() done for 2018\n",
      "Arquivo de 2018 incluído no banco em 763.6537583000027 segundos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_21984\\3537777107.py:10: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy_from_stringio() done for 2019\n",
      "Arquivo de 2019 incluído no banco em 753.461477200035 segundos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_21984\\3537777107.py:10: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy_from_stringio() done for 2020\n",
      "Arquivo de 2020 incluído no banco em 711.7831147999968 segundos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.silva\\AppData\\Local\\Temp\\ipykernel_21984\\3537777107.py:10: DtypeWarning: Columns (3,4,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(caminho_arquivo, delimiter=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy_from_stringio() done for 2021\n",
      "Arquivo de 2021 incluído no banco em 716.8752200999297 segundos.\n"
     ]
    }
   ],
   "source": [
    "con = conecta_db()\n",
    "tm.sleep(1)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2010, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2010 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2011, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2011 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2012, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2012 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2013, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2013 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2014, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2014 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2015, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2015 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2016, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2016 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2017, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2017 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2018, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2018 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2019, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2019 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2020, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2020 incluído no banco em {tempo} segundos.')\n",
    "tm.sleep(30)\n",
    "\n",
    "start = timer()\n",
    "copy_from_stringio(con, 2021, 'tb_rais_estabelecimento')\n",
    "finish = timer()\n",
    "tempo = finish - start\n",
    "print(f'Arquivo de 2021 incluído no banco em {tempo} segundos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749e682",
   "metadata": {},
   "source": [
    "Aproximadamente 2h e 37 minutos para escrever todos os registros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
